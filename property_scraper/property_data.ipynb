{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from fix_addresses_master import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the address junction table \n",
    "df = pd.read_csv('~/Dropbox (GaTech)/CDS-2019-AlbanyHub/ToDatabase/addr_junct_table.csv')\n",
    "directory = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json' #dir of json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(directory+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['identifier', 'lot', 'area', 'address', 'location', 'summary', 'utilities', 'sale', 'building', 'assessment', 'vintage'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at all the values available for a single home\n",
    "example_entry = j_list[0][0]\n",
    "example_entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30721"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate j_list into a single list\n",
    "data = [y for x in j_list for y in x]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_split(data):\n",
    "    #separate these out by the major keys\n",
    "    all_identifiers = [x['identifier'] for x in data if len(x)>0]\n",
    "    all_lot = [x['lot'] for x in data if len(x)>0]\n",
    "    all_area = [x['area'] for x in data if len(x)>0]\n",
    "    all_addresses = [x['address'] for x in data if len(x)>0]\n",
    "    all_location = [x['location'] for x in data if len(x)>0]\n",
    "    all_summary = [x['summary'] for x in data if len(x)>0]\n",
    "    all_utilities = [x['utilities']for x in data if len(x)>0]\n",
    "    all_sale = [x['sale'] for x in data if len(x)>0]\n",
    "    all_building = [x['building'] for x in data if len(x)>0]\n",
    "    all_assessment = [x['assessment'] for x in data if len(x)>0]\n",
    "    all_vintage = [x['vintage'] for x in data if len(x)>0]\n",
    "    #convert data from a multi-layered dict into a single dict for a pandas dataframe\n",
    "    dict_full = {\n",
    "        'address':[x['line1'] for x in all_addresses],\n",
    "        'lot_size':[x['lotSize1'] for x in all_lot],\n",
    "        'zoningType': [x.get('zoningType') for x in all_lot],\n",
    "        'siteZoningIdent': [x.get('siteZoningIdent') for x in all_lot],\n",
    "        'propClass': [x['propClass'] for x in all_summary],\n",
    "        'yearBuilt':[x['yearBuilt'] for x in all_summary],\n",
    "        'size':[x['size']['grossSizeAdjusted'] for x in all_building],\n",
    "        'baths':[x['rooms']['bathsTotal'] for x in all_building],\n",
    "        'beds':[x['rooms']['beds'] for x in all_building],\n",
    "        'rooms':[x['rooms']['roomsTotal'] for x in all_building],\n",
    "        'floors':[x['interior'].get('floors') for x in all_building],\n",
    "        'condition':[x['construction'].get('condition') for x in all_building],\n",
    "        'foundationType':[x['construction'].get('foundationType') for x in all_building],\n",
    "        'roofCover':[x['construction'].get('roofCover') for x in all_building],\n",
    "        'wallType':[x['construction'].get('wallType') for x in all_building],\n",
    "        'improvementYear':[x['construction'].get('propertyStructureMajorImprovementsYear') for x in all_building],\n",
    "        'assessment':[x['assessed']['assdTtlValue'] for x in all_assessment],\n",
    "        'market':[x['market']['mktTtlValue'] for x in all_assessment]\n",
    "    }\n",
    "    return pd.DataFrame(data=dict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26931"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to pandas dataframe\n",
    "dfp = prop_split(data)\n",
    "dfp.drop_duplicates(subset=\"address\")\n",
    "dfp.index = range(len(dfp))\n",
    "len(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in fix_series(dfp['address'])] #id of each addresss in new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the locs where x is not in the address junction table\n",
    "nf = [dfp.loc[x, 'address'] for x in range(len(prim_ids)) if prim_ids[x]==NOT_FOUND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0244699417028703"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nf)/len(prim_ids) #about 3% of addresses were not found despite the successful api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['PrimaryId'] = prim_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 0's with None for clarity\n",
    "dfp.loc[dfp['yearBuilt'] == 0, 'yearBuilt']=None\n",
    "dfp.loc[dfp['size']==0, 'size'] = None\n",
    "dfp.loc[dfp['lot_size'] == 0, 'lot_size'] = None\n",
    "dfp.loc[dfp['assessment'] ==0, 'assessment']=None\n",
    "dfp.loc[dfp['market'] == 0, 'market']=None\n",
    "#Drop rows where address is Not found\n",
    "dfp.loc[dfp['PrimaryId'] == NOT_FOUND, :] = None\n",
    "dfp = dfp.dropna(how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at all the missing data and try to load it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df[~df['Id'].isin(dfp['PrimaryId'])]\n",
    "#missing.to_csv(\"missing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.to_csv(directory+'/property_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "### 1. Identifiers\n",
    "Address (Primary ID) - linked with junction table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Counts of Observations\n",
    "Get counts and percentages of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp)/len(data) # about 86% of addresses have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['size'].notnull()])/len(data) #about 83% of addresses have info on square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['yearBuilt'].notnull()])/len(data) #similarly about 83% of addresses have year built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) #number of addresses in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp) #number of addresses successfully retrieved from database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Some example records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp.loc[[5000, 10000, 15000, 20000, 25000], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fields\n",
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(l):\n",
    "    print(\"Min:\", min(l))\n",
    "    print(\"Max:\", max(l))\n",
    "    print(\"Mean:\",l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lot Size\")\n",
    "get_stats(dfp['lot_size'])\n",
    "print(\"Year Built\")\n",
    "get_stats(dfp['yearBuilt'])\n",
    "print(\"Size (sq ft)\")\n",
    "get_stats(dfp['size'])\n",
    "print('assessment')\n",
    "get_stats(dfp['assessment'])\n",
    "print('market')\n",
    "get_stats(dfp['market'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny lot size\n",
    "dfp.loc[dfp['lot_size']<0.02, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large lot size\n",
    "dfp.loc[dfp['lot_size']>10000, :] # this is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small size\n",
    "dfp[dfp['size']<250] # nothing ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large size\n",
    "dfp[dfp['size']>200000] #largest are commercial, industrial, distribution,etc - checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: difference between market and assessment? (market is often >2x assessment value)\n",
    "https://www.realtor.com/advice/sell/assessed-value-vs-market-value-difference/<br>\n",
    "Market: what home could sell for<br>\n",
    "Assessed: Used for property tax<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']<500] #most low values are vacant properties, 5200 radium springs is a power plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']>10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['assessment']<500] #Vacant properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['zoningType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['siteZoningIdent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['propClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['wallType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['roofCover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['foundationType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Statistical summaries by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g1 = dfp.loc[:,['zoningType','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='zoningType')\n",
    "pd.set_option('precision', 2)\n",
    "dfp_g1.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['propClass','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='propClass')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['condition','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='condition')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g3 = dfp.groupby(by=['condition', 'propClass']) \n",
    "dfp_g3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g4 = dfp.groupby(by=['siteZoningIdent', 'propClass']) \n",
    "dfp_g4.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read missing back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4583, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.index = range(len(missing))\n",
    "missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dir = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing'\n",
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "flist = os.listdir(missing_dir)\n",
    "flist.sort()\n",
    "for filename in flist:\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(missing_dir+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = [y for x in j_list for y in x]\n",
    "data_found =[]#The data returned by the attom api\n",
    "orig_addresses = [] #The addresses used to query the attom api\n",
    "missing_list = pd.DataFrame(data={'Address':[], 'StatusMSG':[], 'Code':[]}) #the return values of addresses which were still not coded\n",
    "for i in range(len(data_new)):\n",
    "    if len(data_new[i])==8 or len(data_new[i])==6:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':data_new[i]['msg'], 'Code':data_new[i]['code']}, ignore_index=True)\n",
    "    elif len(data_new[i])==0:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':'unknown', 'Code':0}, ignore_index=True)\n",
    "    else:\n",
    "        data_found.append(data_new[i])\n",
    "        orig_addresses.append(missing.iloc[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projects that were found when the api was queried again\n",
    "dfp2 = prop_split(data_found)\n",
    "dfp2.drop_duplicates(subset=\"address\")\n",
    "dfp2.index = range(len(dfp2))\n",
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in orig_addresses] #id of each addresss in new dataframe\n",
    "dfp2['PrimaryId'] = prim_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the addresses returned by attom api to those which were queried -> is there a difference?\n",
    "data_found_lat = [float(x['location']['latitude']) for x in data_found]\n",
    "data_found_lon = [float(x['location']['longitude']) for x in data_found]\n",
    "data_found_acc = [x['location']['accuracy'] for x in data_found]\n",
    "df_subset = df[df['Address'].isin(orig_addresses)]\n",
    "df_subset.index = range(len(df_subset))\n",
    "\n",
    "df_compare = pd.DataFrame(data={'found_addresses':dfp2['address'], 'orig_addresses':df_subset['Address'], 'accuracy':data_found_acc,'found_lat':data_found_lat, 'found_lon':data_found_lon, 'orig_lat':df_subset['Xcoord'], 'orig_lon':df_subset['Ycoord']})\n",
    "df_compare['coord_diff'] = df_compare['found_lat']+df_compare['found_lon']-df_compare['orig_lat']-df_compare['orig_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addresses which may have been miscoded: difference in coordinates is significant\n",
    "df_compare[df_compare['coord_diff']>0.005]\n",
    "#US highway addresses: found is more accurate\n",
    "#all else: original is more accurate\n",
    "#Despite incorrect geocoding, likely only the E/W N/S mixups and wildly incorrect addresses are wrong\n",
    "#That is, 80, 97, 190, 553, 676, 734\n",
    "drop_idx = [80, 97, 190, 553, 676, 734]\n",
    "nf_miscoded = dfp2.loc[drop_idx, 'address']\n",
    "dfp2.drop(drop_idx, inplace=True)\n",
    "dfp2.index = range(len(dfp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StatusMSG</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Geocoder Results Address Not Identified.</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success without results. No data available for this address.</th>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuccessWithoutResult</th>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System Not Responding.</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Address  Code\n",
       "StatusMSG                                                        \n",
       "Geocoder Results Address Not Identified.                 84    84\n",
       "Success without results. No data available for ...      474   474\n",
       "SuccessWithoutResult                                   3221  3221\n",
       "System Not Responding.                                   11    11"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list.groupby(by='StatusMSG').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>StatusMSG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3221</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210.0</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212.0</th>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Address  StatusMSG\n",
       "Code                      \n",
       "-2.0         11         11\n",
       " 1.0       3221       3221\n",
       " 210.0       84         84\n",
       " 212.0      474        474"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list.groupby(by='Code').count()\n",
    "#-2 = System Not Responding : There is a failure within the api\n",
    "#1 = SuccessWithoutResult : Your request was successful but returned no results\n",
    "#210 = Geocoder Search Results Address Not Identified. : The input address could not be identified. Please try again.\n",
    "#212 = \tSuccess without results. No data available for this address. : The input address has been located with ZIP level precision, but a record is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerun parts after definition of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-5ecf51a4fec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StatusMSG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'System Not Responding.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnf_miscoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#.to_csv('missing_notresponding.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: append() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "missing_list[missing_list['StatusMSG']=='System Not Responding.'].to_csv('missing_notresponding.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>StatusMSG</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235 BONNY VIEW AVE</td>\n",
       "      <td>Success without results. No data available for...</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>109 W BROAD AVE</td>\n",
       "      <td>Success without results. No data available for...</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>252 BONNY VIEW AVE</td>\n",
       "      <td>Success without results. No data available for...</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>243 BONNY VIEW AVE</td>\n",
       "      <td>Success without results. No data available for...</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>247 BONNY VIEW AVE</td>\n",
       "      <td>Success without results. No data available for...</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Address                                          StatusMSG  \\\n",
       "2  235 BONNY VIEW AVE  Success without results. No data available for...   \n",
       "5     109 W BROAD AVE  Success without results. No data available for...   \n",
       "6  252 BONNY VIEW AVE  Success without results. No data available for...   \n",
       "7  243 BONNY VIEW AVE  Success without results. No data available for...   \n",
       "8  247 BONNY VIEW AVE  Success without results. No data available for...   \n",
       "\n",
       "    Code  \n",
       "2  212.0  \n",
       "5  212.0  \n",
       "6  212.0  \n",
       "7  212.0  \n",
       "8  212.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Success without results. No data available for this address.'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>StatusMSG</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>82 W US HIGHWAY</td>\n",
       "      <td>Geocoder Results Address Not Identified.</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3602 BROOKHOLLOW PKWY</td>\n",
       "      <td>Geocoder Results Address Not Identified.</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>E OGLETHORPE BLVD</td>\n",
       "      <td>Geocoder Results Address Not Identified.</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>E WADDELL AVE</td>\n",
       "      <td>Geocoder Results Address Not Identified.</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>CASON ST</td>\n",
       "      <td>Geocoder Results Address Not Identified.</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Address                                 StatusMSG   Code\n",
       "58         82 W US HIGHWAY  Geocoder Results Address Not Identified.  210.0\n",
       "152  3602 BROOKHOLLOW PKWY  Geocoder Results Address Not Identified.  210.0\n",
       "172      E OGLETHORPE BLVD  Geocoder Results Address Not Identified.  210.0\n",
       "177          E WADDELL AVE  Geocoder Results Address Not Identified.  210.0\n",
       "255               CASON ST  Geocoder Results Address Not Identified.  210.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Geocoder Results Address Not Identified.'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No response resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/mirabel/Dropbox/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing/noresponse/json_dump_missing_noresponse0_10.json')\n",
    "data_nr = json.load(f)\n",
    "f.close()\n",
    "dfp3 = prop_split(data_nr)\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in dfp3['address']] #id of each addresss in new dataframe\n",
    "#manually fix one value\n",
    "prim_ids[6] = id_dict.get('600 POLARIS DR')\n",
    "dfp3['PrimaryId'] = prim_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8811562123628788"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2, dfp3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = missing_list[missing_list['StatusMSG']!='System Not Responding.']\n",
    "p2 = p1.append([{'Address':x} for x in nf_miscoded], ignore_index=True)\n",
    "#\n",
    "p2.tail(20)\n",
    "p2.to_csv('missing_unresolved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80             320 N JACKSON ST\n",
       "97     1212 WHISPERING PINES RD\n",
       "190             200 E BROAD AVE\n",
       "553            1401 E BROAD AVE\n",
       "676           2100 N FULTON AVE\n",
       "734                639 OWENS ST\n",
       "Name: address, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "cds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
