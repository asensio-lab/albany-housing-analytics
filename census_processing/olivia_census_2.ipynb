{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in Datasets\n",
    "Read all csv files from the tract and blockgroup folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = {} # the keys are the names of the files, and the values are the dataframes read from them\n",
    "#READ AND RENAME FILES\n",
    "PATH1 = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Census/tract_data'\n",
    "PATH2 = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Census/blockgroup_data'\n",
    "for folder in os.listdir(PATH2):\n",
    "    #get all the files that are stored in folders\n",
    "    if os.path.isdir(PATH2+'/'+folder):\n",
    "        for file in os.listdir(PATH2+'/'+folder):\n",
    "            if file.endswith('_with_ann.csv'):\n",
    "                df_all[folder] = pd.read_csv(PATH2+'/'+folder+'/'+file)\n",
    "    else:\n",
    "        df_all[folder[:-4]] = pd.read_csv(PATH2+'/'+folder)\n",
    "        \n",
    "for folder in os.listdir(PATH1):\n",
    "    #get all the files that are stored in folders\n",
    "    if os.path.isdir(PATH1+'/'+folder):\n",
    "        for file in os.listdir(PATH1+'/'+folder):\n",
    "            if file.endswith('_with_ann.csv'):\n",
    "                df_all[folder] = pd.read_csv(PATH1+'/'+folder+'/'+file)\n",
    "    else:\n",
    "        df_all[folder[:-4]] = pd.read_csv(PATH1+'/'+folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 459)\n",
      "(44, 219)\n",
      "(44, 219)\n"
     ]
    }
   ],
   "source": [
    "#fix tract 2017 age data\n",
    "master_col_names = pd.read_csv(PATH1+'/10_tract_age/ACS_10_5YR_S0101_metadata.csv', header=None)\n",
    "df = df_all['17_tract_age'].copy()\n",
    "print(df.shape)\n",
    "master_col_names.columns = ['label', 'desc']\n",
    "name_dict= {master_col_names.loc[i, 'desc']:master_col_names.loc[i, 'label'] for i in range(len(master_col_names))}\n",
    "df.columns = range(len(df.columns))\n",
    "for c in df.columns:\n",
    "    if df.loc[0,c] in name_dict.keys():\n",
    "        df.rename(columns={c:name_dict[df.loc[0,c]]}, inplace=True)\n",
    "    else:\n",
    "        df.drop(columns=c, inplace=True)\n",
    "for k, v in name_dict.items():\n",
    "    if v not in df.columns:\n",
    "        df[v] = np.nan\n",
    "df_all['17_tract_age'] = df\n",
    "print(df.shape)\n",
    "print(df_all['14_tract_age'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(44, 243)\n",
      "(44, 283)\n",
      "11\n",
      "(44, 243)\n",
      "(44, 283)\n",
      "12\n",
      "(44, 243)\n",
      "(44, 283)\n",
      "13\n",
      "(44, 243)\n",
      "(44, 283)\n",
      "14\n",
      "(44, 243)\n",
      "(44, 283)\n"
     ]
    }
   ],
   "source": [
    "#fix tract employment data\n",
    "master_col_names = pd.read_csv(PATH1+'/17_tract_emp/ACS_17_5YR_S2301_metadata.csv', header=None)\n",
    "master_col_names.columns = ['label', 'desc']\n",
    "name_dict= {master_col_names.loc[i, 'desc']:master_col_names.loc[i, 'label'] for i in range(len(master_col_names))}\n",
    "for year in range(10, 15):\n",
    "    df = df_all[str(year)+'_tract_emp'].copy()\n",
    "    print(year)\n",
    "    print(df.shape)\n",
    "    RENAME = {}\n",
    "    for c in df.columns:\n",
    "        if df.loc[0,c] in name_dict.keys():\n",
    "            RENAME[c] = name_dict[df.loc[0,c]]\n",
    "        else:\n",
    "            df.drop(columns=c, inplace=True)\n",
    "    df.rename(columns=RENAME, inplace=True)        \n",
    "    for k, v in name_dict.items():\n",
    "        if v not in df.columns:\n",
    "            df[v] = np.nan\n",
    "    df_all[str(year)+'_tract_emp'] = df\n",
    "    print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_types = {}\n",
    "type_prefix = {}\n",
    "for k in df_all.keys():\n",
    "    df_types[k[3:]] = [] \n",
    "type_prefix['blockgroup_age'] = 'ab'\n",
    "type_prefix['blockgroup_employment'] = 'e'\n",
    "type_prefix['blockgroup_population'] = 'p'\n",
    "type_prefix['blockgroup_income'] = 'i'\n",
    "type_prefix['blockgroup_race'] = 'rb'\n",
    "type_prefix['blockgroup_vacancy'] = 'v'\n",
    "type_prefix['blockgroup_owner_renter'] = 'or'\n",
    "type_prefix['tract_age'] = 'at'\n",
    "type_prefix['tract_race'] = 'rt'\n",
    "type_prefix['tract_emp'] = 'et'\n",
    "type_prefix['tract_medinc'] = 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up fields and add a column for year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Convert Geo Display label into 3 separatecolumns\n",
    "#Clean several different census labels\n",
    "re_string1 = 'Census Tract (\\d+(?:.\\d+)?)'\n",
    "re_string2 = 'Block Group (\\d+(?:.\\d+)?)'\n",
    "for k, v in df_all.items():\n",
    "    #Add Year column\n",
    "    year = \"20\"+k[:2]\n",
    "    v['Year'] = int(year)\n",
    "    if 'blockgroup' in k:\n",
    "        #Split geo display label\n",
    "        new = v[\"GEO.display-label\"].str.split(\", \", expand = True)\n",
    "        v[\"block\"] = new[0] \n",
    "        v[\"tract\"] = new[1] \n",
    "        v[\"county\"] = new[2] \n",
    "        v.drop('GEO.display-label', axis = 1, inplace=True)\n",
    "        \n",
    "        #Get block number out of 'Block Group xx.xx'\n",
    "        l = len(v['block'])\n",
    "        for i in range(1,l):\n",
    "            s = v.loc[i, 'block']\n",
    "            m = re.search(re_string2, s)\n",
    "            v.loc[i, 'block'] = m.group(1)    \n",
    "        #reorder columns\n",
    "        cols = list(v.columns)\n",
    "        cols.insert(2, 'tract')\n",
    "        cols.insert(3, 'block')\n",
    "        cols.insert(4, 'county')\n",
    "        cols.insert(5, 'Year')\n",
    "        del cols[-4]\n",
    "        del cols[-3]\n",
    "        del cols[-2]\n",
    "        del cols[-1]\n",
    "        v = v.reindex(columns=cols).rename(columns={'block':'blockgroup'})\n",
    "    elif 'tract' in k:\n",
    "        #Split geo display label\n",
    "        new = v[\"GEO.display-label\"].str.split(\", \", expand = True)\n",
    "        v[\"tract\"] = new[0] \n",
    "        v[\"county\"] = new[1]\n",
    "        v.drop('GEO.display-label', axis = 1, inplace=True)\n",
    "        #reorder columns\n",
    "        cols = list(v.columns)\n",
    "        cols.insert(2, 'tract')\n",
    "        cols.insert(3, 'county')\n",
    "        cols.insert(4, 'Year')\n",
    "        del cols[-3]\n",
    "        del cols[-2]\n",
    "        del cols[-1]\n",
    "        v = v.reindex(columns=cols)\n",
    "    else:\n",
    "        print('ERR')\n",
    "    #FIX tract\n",
    "    l = len(v['tract'])\n",
    "    #get tract number out of 'Census Tract xx.xx'\n",
    "    for i in range(1,l):\n",
    "        s = v.loc[i, 'tract']\n",
    "        m = re.search(re_string1, s)\n",
    "        v.loc[i, 'tract'] = m.group(1)\n",
    "    #Change tract label to bring in line with other source\n",
    "    for i in range(1,l):\n",
    "        if '.' in v.loc[i, 'tract']:\n",
    "            s = v.loc[i, 'tract'].split('.')\n",
    "            if len(s[0]) >=1 and len(s[0]) <= 3:\n",
    "                v.loc[i, 'tract'] = s[0] + s[1]\n",
    "        else:\n",
    "            if len(v.loc[i, 'tract']) >=1 and len(v.loc[i, 'tract']) <=4:\n",
    "                v.loc[i, 'tract'] = v.loc[i, 'tract'] + '00'   \n",
    "    df_all[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all years in long format per census type\n",
    "for k,v in df_all.items():\n",
    "    #Add the suffix \n",
    "    v = v.copy()\n",
    "    pre = type_prefix[k[3:]]+'_'\n",
    "    if 'tract' in k:\n",
    "        cols = v.columns[5:]\n",
    "    elif 'blockgroup' in k:\n",
    "        cols = v.columns[6:]\n",
    "    cols = {c:pre+c for c in cols}\n",
    "    v.rename(columns=cols, inplace=True)\n",
    "    df_types[k[3:]].append(v)\n",
    "#Concatenate all the different years\n",
    "for k, v in df_types.items():\n",
    "    df_types[k] = pd.concat(df_types[k], sort=False)\n",
    "    df_types[k].index = range(len(df_types[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine type of census record in wide format\n",
    "BLOCK = [df_types[k].sort_values(by=['Year', 'tract', 'blockgroup']).set_index(['GEO.id', 'Year']) for k in df_types.keys() if 'blockgroup' in k]\n",
    "TRACT = [df_types[k].sort_values(by=['Year', 'tract'], ascending=False).set_index('GEO.id') for k in df_types.keys() if 'tract' in k]\n",
    "\n",
    "df_b = pd.concat(BLOCK, axis=1)\n",
    "df_b = df_b.loc[:,~df_b.columns.duplicated()] #drop duplicate columns\n",
    "df_t = pd.concat(TRACT, axis=1)\n",
    "df_t = df_t.loc[:,~df_t.columns.duplicated()] #drop duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unnecessary columns and make column names descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop \"Margin of error\" columns\n",
    "for c in df_b.columns:\n",
    "    if 'HD02' in c:\n",
    "        df_b.drop(columns=c, inplace=True)\n",
    "for c in df_t.columns:\n",
    "    if 'MOE' in c:\n",
    "        df_t.drop(columns=c, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename some columns by hand\n",
    "df_b = df_b.rename(columns={'p_HD01_VD01': 'TotalPopulation', 'e_HD01_VD01': 'TotalLabor',\n",
    "                             'e_HD01_VD02': 'TotalInLaborforce', 'e_HD01_VD03': 'TotalCivilLabor',\n",
    "                             'e_HD01_VD04': 'EmployedCivlLabor', 'e_HD01_VD05': 'UnemployedCivilLabor',\n",
    "                             'e_HD01_VD06': 'TotalArmedForces', 'e_HD01_VD07': 'TotalNotInLaborforce',\n",
    "                             'v_HD01_VD01': 'TotalHomes', 'v_HD01_VD02': 'TotalOccupiedHomes',\n",
    "                             'v_HD01_VD03': 'TotalVacantHomes',\n",
    "                             'or_HD01_VD02': 'TotalOwnedHomes', 'or_HD01_VD03': 'TotalRentedHomes'})\n",
    "labelst = df_t.loc['Id'].copy()\n",
    "labelsb = df_b.loc['Id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordreplace= {\n",
    "    'Employment':'Emp',\n",
    "    'Unemployment':'Unemp',\n",
    "    'LaborForceParticipation':'LFP',\n",
    "    \n",
    "    'Estimate':'',\n",
    "    'EducationalAttainment':'Edu',\n",
    "    'Population':'',\n",
    "    'RaceAndHispanicOrLatinoOrigin':'',\n",
    "    'Years':'',\n",
    "    'Sex':'',\n",
    "    'PovertyStatusInThePast12Months':'',\n",
    "    'DisabilityStatus':'',\n",
    "    'SummaryIndicators':'',\n",
    "    'IncomeDollars':'',\n",
    "\n",
    "    'BachelorSDegreeOrHigher':'Bachelors',\n",
    "    'SomeCollegeOrAssociateSDegree':'SomeCollege',\n",
    "    'HighSchoolGraduateIncludesEquivalency':'HS',\n",
    "    'LessThanHighSchoolGraduate':'LessHS',\n",
    "    \n",
    "    'WithAnyDisability':'Disabled',\n",
    "    \n",
    "    'WhiteAlone':'White',  \n",
    "    'BlackOrAfricanAmericanAlone':'Black',\n",
    "    'AmericanIndianAndAlaskaNativeAlone':'Native',\n",
    "    'AsianAlone':'Asian',\n",
    "    'NativeHawaiianAndOtherPacificIslanderAlone':'PacificIslander',\n",
    "    'SomeOtherRaceAlone':'OtherRace',\n",
    "    'NotHispanicOrLatino':'NonHispanic',\n",
    "    'HispanicOrLatino':'Hispanic',\n",
    "    'Origin':'',\n",
    "    'HispanicOfAnyRace':'Hispanic',\n",
    "    \n",
    "    'TwoOrMoreRaces':'2Plus',\n",
    "    'TwoRacesExcludingSomeOtherRaceAndThreeOrMoreRaces':'ExcOther',\n",
    "    'TwoRacesIncludingSomeOtherRace':'IncOther',\n",
    "    \n",
    "    'WithOwnChildrenUnder18W':'W',\n",
    "    'WithOwnChildren':'Children',\n",
    "    'Only':'',\n",
    "    'Under6To17':'6To17',\n",
    "    \n",
    "    'BelowPovertyLevel':'BPL',\n",
    "    'AtOrAboveThePovertyLevel':'APL',\n",
    "    \n",
    "    'RatioMalesPer100Females':'SexRatio',\n",
    "    \n",
    "    'MarriedCoupleFamilies':'MIncome',\n",
    "    'NonfamilyHouseholds':'NfIncome',\n",
    "    'Households':'HIncome',\n",
    "    'Families':'FIncome',\n",
    "    '00000':'00k',\n",
    "    '0000':'0k',\n",
    "    '000':'k',\n",
    "    \n",
    " }\n",
    "#BLOCK LEVEL\n",
    "desc = {}\n",
    "DROP = ['or_HD01_VD01']\n",
    "for c in labelsb.columns:\n",
    "    if 'HD' in c:\n",
    "        desc[c] = labelsb[c][2013]\n",
    "for k, v in desc.items():\n",
    "    words = re.split('[^a-zA-Z0-9]',  v.title())\n",
    "    r = ''.join(words)\n",
    "    for w1, w2 in wordreplace.items():\n",
    "        r = r.replace(w1, w2)\n",
    "    #if it is total, it is a repeat\n",
    "    if r == 'Total':\n",
    "        DROP.append(k)\n",
    "    else:\n",
    "        RENAME[k] = r\n",
    "# #df_b[['ab_HD01_VD01', 'rb_HD01_VD01','total_pop', 'r_HD01_VD01','total_occ_homes']] -> these three are repeats\n",
    "df_b.drop(columns=DROP, inplace=True, errors='ignore')\n",
    "df_b.rename(columns=RENAME, inplace=True)\n",
    "\n",
    "df_b.rename(columns={'Male':'TotalMale', 'Female':'TotalFemale'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tract Level\n",
    "desc = {}\n",
    "DROP = ['rt_HD01_VD01']\n",
    "RENAME={}\n",
    "\n",
    "for c in labelst.columns:\n",
    "    if 'HD' in c or 'HC' in c:\n",
    "        desc[c] = labelst[c].iloc[0]\n",
    "        \n",
    "\n",
    "for k, v in desc.items():\n",
    "    if type(v)==float:\n",
    "        DROP.append(k)\n",
    "    elif 'SELECTED AGE CATEGORIES' in v or 'Margin of Error' in v or 'PERCENT ALLOCATED' in v or 'SUMMARY INDICATORS' in v:\n",
    "        DROP.append(k)\n",
    "    elif v == 'Total; Estimate; Total population':\n",
    "        RENAME[k] = 'TotalPopulation'\n",
    "    elif v == 'Households; Estimate; Total':\n",
    "        RENAME[k] = 'HTotal'\n",
    "    elif v == 'Families; Estimate; Total':\n",
    "        RENAME[k] = 'FTotal'\n",
    "    elif v == 'Married-couple families; Estimate; Total':\n",
    "        RENAME[k] = 'MTotal'\n",
    "    elif v == 'Nonfamily households; Estimate; Total':\n",
    "        RENAME[k] = 'NfTotal'\n",
    "    elif k[0:2] == 'et' or k[0:2] == 'at' or k[0:2] == 'rt' or k[0:1]=='m':\n",
    "        words = re.split('[^a-zA-Z0-9]',  v.title())\n",
    "        r = ''.join(words)\n",
    "        for w1, w2 in wordreplace.items():\n",
    "            r = r.replace(w1, w2)\n",
    "        RENAME[k] = r\n",
    "# #df_b[['ab_HD01_VD01', 'rb_HD01_VD01','total_pop', 'r_HD01_VD01','total_occ_homes']] -> these three are repeats\n",
    "df_t.drop(columns=DROP, inplace=True, errors='ignore')\n",
    "df_t.rename(columns=RENAME, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 273)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.to_csv('CensusTract.csv')\n",
    "df_b.to_csv('CensusBlock.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tract land area clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = df_land_area[\"GEO.display-label\"].str.split(\", \", expand = True)\n",
    "df_land_area[\"county\"] = new2[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_area = df_land_area.drop('GEO.display-label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_area['tract'] = df_land_area['GCT_STUB.display-label.1'] \n",
    "df_land_area = df_land_area.drop('GCT_STUB.display-label.1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_land_area['tract'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(df_land_area['tract'])\n",
    "df_land_area1 = df_land_area.copy()\n",
    "re_string = 'Census Tract (\\d+(?:.\\d+)?)'\n",
    "for i in range(2,l):\n",
    "    s = df_land_area.loc[i, 'tract']\n",
    "    m = re.search(re_string, s)\n",
    "    df_land_area1.loc[i, 'tract'] = m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_series = df_land_area1['tract']\n",
    "l = len(df_land_area1['tract'])\n",
    "for i in range(1,l):\n",
    "    if '.' in tract_series[i]:\n",
    "        s = tract_series[i].split('.')\n",
    "        if len(s[0]) == 1:\n",
    "            tract_series[i] = s[0] + s[1]\n",
    "        elif len(s[0]) == 2:\n",
    "            tract_series[i] = s[0] + s[1]\n",
    "        elif len(s[0]) == 3:\n",
    "            tract_series[i] = s[0] + s[1]\n",
    "    else:\n",
    "        if len(tract_series[i]) == 3:\n",
    "            tract_series[i] = df_land_area1['tract'][i] + '00'\n",
    "        elif len(tract_series[i]) == 2:\n",
    "            tract_series[i] = df_land_area1['tract'][i] + '00'\n",
    "        elif len(tract_series[i]) == 1:\n",
    "            tract_series[i] = df_land_area1['tract'][i] + '00'\n",
    "        elif len(tract_series[i]) == 4:\n",
    "            tract_series[i] = df_land_area1['tract'][i] + '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_area1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new column for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inc1['block_tract'] = df_inc1['block'] + '_' + df_inc1['tract']\n",
    "df_inc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop1['block_tract'] = df_pop1['block'] + '_' + df_pop1['tract']\n",
    "df_pop1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = list(df_land_area1)\n",
    "\n",
    "cols.insert(14, cols.pop(cols.index('tract')))\n",
    "df_land_area1 = df_land_area1.loc[:, cols]\n",
    "\n",
    "#len(cols)\n",
    "df_land_area1.drop(1, axis=0, inplace=True)\n",
    "df_land_area1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
