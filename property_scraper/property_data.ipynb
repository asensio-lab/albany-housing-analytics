{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from fix_addresses_master import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the address junction table \n",
    "df = pd.read_csv('~/Dropbox (GaTech)/CDS-2019-AlbanyHub/ToDatabase/addr_junct_table.csv')\n",
    "directory = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json' #dir of json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(directory+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['identifier', 'lot', 'area', 'address', 'location', 'summary', 'utilities', 'sale', 'building', 'assessment', 'vintage'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at all the values available for a single home\n",
    "example_entry = j_list[0][0]\n",
    "example_entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30721"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate j_list into a single list\n",
    "data = [y for x in j_list for y in x]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_split(data):\n",
    "    #separate these out by the major keys\n",
    "    all_identifiers = [x['identifier'] for x in data if len(x)>0]\n",
    "    all_lot = [x['lot'] for x in data if len(x)>0]\n",
    "    all_area = [x['area'] for x in data if len(x)>0]\n",
    "    all_addresses = [x['address'] for x in data if len(x)>0]\n",
    "    all_location = [x['location'] for x in data if len(x)>0]\n",
    "    all_summary = [x['summary'] for x in data if len(x)>0]\n",
    "    all_utilities = [x['utilities']for x in data if len(x)>0]\n",
    "    all_sale = [x['sale'] for x in data if len(x)>0]\n",
    "    all_building = [x['building'] for x in data if len(x)>0]\n",
    "    all_assessment = [x['assessment'] for x in data if len(x)>0]\n",
    "    all_vintage = [x['vintage'] for x in data if len(x)>0]\n",
    "    #convert data from a multi-layered dict into a single dict for a pandas dataframe\n",
    "    dict_full = {\n",
    "        'address':[x['line1'] for x in all_addresses],\n",
    "        'lot_size':[x['lotSize1'] for x in all_lot],\n",
    "        'zoningType': [x.get('zoningType') for x in all_lot],\n",
    "        'siteZoningIdent': [x.get('siteZoningIdent') for x in all_lot],\n",
    "        'propClass': [x['propClass'] for x in all_summary],\n",
    "        'yearBuilt':[x['yearBuilt'] for x in all_summary],\n",
    "        'size':[x['size']['grossSizeAdjusted'] for x in all_building],\n",
    "        'baths':[x['rooms']['bathsTotal'] for x in all_building],\n",
    "        'beds':[x['rooms']['beds'] for x in all_building],\n",
    "        'rooms':[x['rooms']['roomsTotal'] for x in all_building],\n",
    "        'floors':[x['interior'].get('floors') for x in all_building],\n",
    "        'condition':[x['construction'].get('condition') for x in all_building],\n",
    "        'foundationType':[x['construction'].get('foundationType') for x in all_building],\n",
    "        'roofCover':[x['construction'].get('roofCover') for x in all_building],\n",
    "        'wallType':[x['construction'].get('wallType') for x in all_building],\n",
    "        'improvementYear':[x['construction'].get('propertyStructureMajorImprovementsYear') for x in all_building],\n",
    "        'assessment':[x['assessed']['assdTtlValue'] for x in all_assessment],\n",
    "        'market':[x['market']['mktTtlValue'] for x in all_assessment]\n",
    "    }\n",
    "    return pd.DataFrame(data=dict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26931"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to pandas dataframe\n",
    "dfp = prop_split(data)\n",
    "dfp.drop_duplicates(subset=\"address\")\n",
    "dfp.index = range(len(dfp))\n",
    "len(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26931"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in fix_series(dfp['address'])] #id of each addresss in new dataframe\n",
    "len(prim_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the locs where x is not in the address junction table\n",
    "nf = [dfp.loc[x, 'address'] for x in range(len(prim_ids)) if prim_ids[x]==NOT_FOUND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022910400653521963"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nf)/len(prim_ids) #about 3% of addresses were not found despite the successful api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26931"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['PrimaryId'] = prim_ids\n",
    "len(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 0's with None for clarity\n",
    "dfp.loc[dfp['yearBuilt'] == 0, 'yearBuilt']=None\n",
    "dfp.loc[dfp['size']==0, 'size'] = None\n",
    "dfp.loc[dfp['lot_size'] == 0, 'lot_size'] = None\n",
    "dfp.loc[dfp['assessment'] ==0, 'assessment']=None\n",
    "dfp.loc[dfp['market'] == 0, 'market']=None\n",
    "#Drop rows where address is Not found\n",
    "dfp.loc[dfp['PrimaryId'] == NOT_FOUND, :] = None\n",
    "dfp = dfp.dropna(how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at all the missing data and try to load it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df[~df['Id'].isin(dfp['PrimaryId'])]\n",
    "missing.to_csv(\"missing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.to_csv(directory+'/property_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "### 1. Identifiers\n",
    "Address (Primary ID) - linked with junction table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Counts of Observations\n",
    "Get counts and percentages of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp)/len(data) # about 86% of addresses have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['size'].notnull()])/len(data) #about 83% of addresses have info on square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['yearBuilt'].notnull()])/len(data) #similarly about 83% of addresses have year built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) #number of addresses in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp) #number of addresses successfully retrieved from database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Some example records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp.loc[[5000, 10000, 15000, 20000, 25000], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fields\n",
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(l):\n",
    "    print(\"Min:\", min(l))\n",
    "    print(\"Max:\", max(l))\n",
    "    print(\"Mean:\",l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lot Size\")\n",
    "get_stats(dfp['lot_size'])\n",
    "print(\"Year Built\")\n",
    "get_stats(dfp['yearBuilt'])\n",
    "print(\"Size (sq ft)\")\n",
    "get_stats(dfp['size'])\n",
    "print('assessment')\n",
    "get_stats(dfp['assessment'])\n",
    "print('market')\n",
    "get_stats(dfp['market'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny lot size\n",
    "dfp.loc[dfp['lot_size']<0.02, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large lot size\n",
    "dfp.loc[dfp['lot_size']>10000, :] # this is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small size\n",
    "dfp[dfp['size']<250] # nothing ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large size\n",
    "dfp[dfp['size']>200000] #largest are commercial, industrial, distribution,etc - checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: difference between market and assessment? (market is often >2x assessment value)\n",
    "https://www.realtor.com/advice/sell/assessed-value-vs-market-value-difference/<br>\n",
    "Market: what home could sell for<br>\n",
    "Assessed: Used for property tax<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']<500] #most low values are vacant properties, 5200 radium springs is a power plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']>10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['assessment']<500] #Vacant properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['zoningType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['siteZoningIdent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['propClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['wallType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['roofCover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['foundationType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Statistical summaries by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g1 = dfp.loc[:,['zoningType','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='zoningType')\n",
    "pd.set_option('precision', 2)\n",
    "dfp_g1.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['propClass','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='propClass')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['condition','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='condition')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g3 = dfp.groupby(by=['condition', 'propClass']) \n",
    "dfp_g3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g4 = dfp.groupby(by=['siteZoningIdent', 'propClass']) \n",
    "dfp_g4.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read missing back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4410, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.index = range(len(missing))\n",
    "missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dir = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing'\n",
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "flist = os.listdir(missing_dir)\n",
    "flist.sort()\n",
    "for filename in flist:\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(missing_dir+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Split the results into 'found', which were retrieved on the second run-through and 'missing_list', which still could not be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9605142e32b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmissing_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StatusMSG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Code'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmissing_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StatusMSG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Code'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cds/cds_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cds/cds_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cds/cds_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n",
      "\u001b[0;32m~/Documents/cds/cds_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/cds/cds_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2137\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "data_new = [y for x in j_list for y in x]\n",
    "data_found =[]#The data returned by the attom api\n",
    "orig_addresses = [] #The addresses used to query the attom api\n",
    "missing_list = pd.DataFrame(data={'Address':[], 'StatusMSG':[], 'Code':[]}) #the return values of addresses which were still not coded\n",
    "for i in range(len(data_new)):\n",
    "    if len(data_new[i])==8 or len(data_new[i])==6:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':data_new[i]['msg'], 'Code':data_new[i]['code']}, ignore_index=True)\n",
    "    elif len(data_new[i])==0:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':'unknown', 'Code':0}, ignore_index=True)\n",
    "    else:\n",
    "        data_found.append(data_new[i])\n",
    "        orig_addresses.append(missing.iloc[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projects that were found when the api was queried again\n",
    "dfp2 = prop_split(data_found)\n",
    "dfp2.drop_duplicates(subset=\"address\")\n",
    "dfp2.index = range(len(dfp2))\n",
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in orig_addresses] #id of each addresss in new dataframe\n",
    "dfp2['PrimaryId'] = prim_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  In found, compare the coordinates that were located to the coordinates of the address used to query. If it seems that the api found the wrong location, drop this address from dfp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the addresses returned by attom api to those which were queried -> is there a difference?\n",
    "data_found_lat = [float(x['location']['latitude']) for x in data_found]\n",
    "data_found_lon = [float(x['location']['longitude']) for x in data_found]\n",
    "data_found_acc = [x['location']['accuracy'] for x in data_found]\n",
    "df_subset = df[df['Address'].isin(orig_addresses)] #The set of the dataframe that was used to generate data_found\n",
    "df_subset.index = range(len(df_subset))\n",
    "\n",
    "df_compare = pd.DataFrame(data={'found_addresses':dfp2['address'], 'orig_addresses':df_subset['Address'], 'accuracy':data_found_acc,'found_lat':data_found_lat, 'found_lon':data_found_lon, 'orig_lat':df_subset['Xcoord'], 'orig_lon':df_subset['Ycoord']})\n",
    "df_compare['coord_diff'] = df_compare['found_lat']+df_compare['found_lon']-df_compare['orig_lat']-df_compare['orig_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addresses which may have been miscoded: difference in coordinates is significant\n",
    "df_compare[df_compare['coord_diff']>0.005]\n",
    "#US highway addresses: found is more accurate\n",
    "#all else: original is more accurate\n",
    "#Despite incorrect geocoding, likely only the E/W N/S mixups and wildly incorrect addresses are wrong\n",
    "#That is, 80, 97, 190, 553, 676, 734\n",
    "drop_idx = [80, 97, 190, 553, 676, 734]\n",
    "nf_miscoded = dfp2.loc[drop_idx, 'address']\n",
    "dfp2.drop(drop_idx, inplace=True)\n",
    "dfp2.index = range(len(dfp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) In missing_list, split the non-found addresses by the error code. Export the addresses which resulted in 'System not responding' to be re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list.groupby(by='StatusMSG').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list.groupby(by='Code').count()\n",
    "#-2 = System Not Responding : There is a failure within the api\n",
    "#1 = SuccessWithoutResult : Your request was successful but returned no results\n",
    "#210 = Geocoder Search Results Address Not Identified. : The input address could not be identified. Please try again.\n",
    "#212 = \tSuccess without results. No data available for this address. : The input address has been located with ZIP level precision, but a record is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='System Not Responding.'].to_csv('missing_notresponding.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Success without results. No data available for this address.'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Geocoder Results Address Not Identified.'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Retrieve the results of step c) and add them to a new dataframe dfp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/mirabel/Dropbox/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing/noresponse/json_dump_missing_noresponse0_10.json')\n",
    "data_nr = json.load(f)\n",
    "f.close()\n",
    "dfp3 = prop_split(data_nr)\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in dfp3['address']] #id of each addresss in new dataframe\n",
    "#manually fix one value\n",
    "prim_ids[6] = id_dict.get('600 POLARIS DR')\n",
    "dfp3['PrimaryId'] = prim_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2, dfp3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = missing_list[missing_list['StatusMSG']!='System Not Responding.']\n",
    "p2 = p1.append([{'Address':x} for x in nf_miscoded], ignore_index=True)\n",
    "#\n",
    "p2.tail(20)\n",
    "p2.to_csv('missing_unresolved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "cds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
