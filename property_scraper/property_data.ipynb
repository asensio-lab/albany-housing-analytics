{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from fix_addresses_master import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the address junction table \n",
    "df = pd.read_csv('~/Dropbox (GaTech)/CDS-2019-AlbanyHub/ToDatabase/addr_junct_table.csv')\n",
    "directory = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json' #dir of json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(directory+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['identifier', 'lot', 'area', 'address', 'location', 'summary', 'utilities', 'sale', 'building', 'assessment', 'vintage'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at all the values available for a single home\n",
    "example_entry = j_list[0][0]\n",
    "example_entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30721"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate j_list into a single list\n",
    "data = [y for x in j_list for y in x]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_split(data):\n",
    "    #separate these out by the major keys\n",
    "    all_identifiers = [x['identifier'] for x in data if len(x)>0]\n",
    "    all_lot = [x['lot'] for x in data if len(x)>0]\n",
    "    all_area = [x['area'] for x in data if len(x)>0]\n",
    "    all_addresses = [x['address'] for x in data if len(x)>0]\n",
    "    all_location = [x['location'] for x in data if len(x)>0]\n",
    "    all_summary = [x['summary'] for x in data if len(x)>0]\n",
    "    all_utilities = [x['utilities']for x in data if len(x)>0]\n",
    "    all_sale = [x['sale'] for x in data if len(x)>0]\n",
    "    all_building = [x['building'] for x in data if len(x)>0]\n",
    "    all_assessment = [x['assessment'] for x in data if len(x)>0]\n",
    "    all_vintage = [x['vintage'] for x in data if len(x)>0]\n",
    "    #convert data from a multi-layered dict into a single dict for a pandas dataframe\n",
    "    dict_full = {\n",
    "        'address':[x['line1'] for x in all_addresses],\n",
    "        'lot_size':[x['lotSize1'] for x in all_lot],\n",
    "        'zoningType': [x.get('zoningType') for x in all_lot],\n",
    "        'siteZoningIdent': [x.get('siteZoningIdent') for x in all_lot],\n",
    "        'propClass': [x['propClass'] for x in all_summary],\n",
    "        'yearBuilt':[x['yearBuilt'] for x in all_summary],\n",
    "        'size':[x['size']['grossSizeAdjusted'] for x in all_building],\n",
    "        'baths':[x['rooms']['bathsTotal'] for x in all_building],\n",
    "        'beds':[x['rooms']['beds'] for x in all_building],\n",
    "        'rooms':[x['rooms']['roomsTotal'] for x in all_building],\n",
    "        'floors':[x['interior'].get('floors') for x in all_building],\n",
    "        'condition':[x['construction'].get('condition') for x in all_building],\n",
    "        'foundationType':[x['construction'].get('foundationType') for x in all_building],\n",
    "        'roofCover':[x['construction'].get('roofCover') for x in all_building],\n",
    "        'wallType':[x['construction'].get('wallType') for x in all_building],\n",
    "        'improvementYear':[x['construction'].get('propertyStructureMajorImprovementsYear') for x in all_building],\n",
    "        'assessment':[x['assessed']['assdTtlValue'] for x in all_assessment],\n",
    "        'market':[x['market']['mktTtlValue'] for x in all_assessment]\n",
    "    }\n",
    "    return pd.DataFrame(data=dict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to pandas dataframe\n",
    "dfp = prop_split(data)\n",
    "print(len(dfp))\n",
    "dfp.drop_duplicates(subset=\"address\", inplace=True)\n",
    "dfp.index = range(len(dfp))\n",
    "len(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26788"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in fix_series(dfp['address'])] #id of each addresss in new dataframe\n",
    "len(prim_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the locs where x is not in the address junction table\n",
    "nf = [dfp.loc[x, 'address'] for x in range(len(prim_ids)) if prim_ids[x]==NOT_FOUND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02269672987905032"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nf)/len(prim_ids) #about 3% of addresses were not found despite the successful api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26788"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['PrimaryId'] = prim_ids\n",
    "len(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 0's with None for clarity\n",
    "dfp.loc[dfp['yearBuilt'] == 0, 'yearBuilt']=None\n",
    "dfp.loc[dfp['size']==0, 'size'] = None\n",
    "dfp.loc[dfp['lot_size'] == 0, 'lot_size'] = None\n",
    "dfp.loc[dfp['assessment'] ==0, 'assessment']=None\n",
    "dfp.loc[dfp['market'] == 0, 'market']=None\n",
    "#Drop rows where address is Not found\n",
    "dfp.loc[dfp['PrimaryId'] == NOT_FOUND, :] = None\n",
    "dfp = dfp.dropna(how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at all the missing data and try to load it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df[~df['Id'].isin(dfp['PrimaryId'])]\n",
    "#missing.to_csv(directory+\"/property_data_missing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.to_csv(directory+'/property_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "### 1. Identifiers\n",
    "Address (Primary ID) - linked with junction table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Counts of Observations\n",
    "Get counts and percentages of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp)/len(data) # about 86% of addresses have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['size'].notnull()])/len(data) #about 83% of addresses have info on square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp[dfp['yearBuilt'].notnull()])/len(data) #similarly about 83% of addresses have year built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) #number of addresses in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfp) #number of addresses successfully retrieved from database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Some example records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp.loc[[5000, 10000, 15000, 20000, 25000], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fields\n",
    "dfp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(l):\n",
    "    print(\"Min:\", min(l))\n",
    "    print(\"Max:\", max(l))\n",
    "    print(\"Mean:\",l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lot Size\")\n",
    "get_stats(dfp['lot_size'])\n",
    "print(\"Year Built\")\n",
    "get_stats(dfp['yearBuilt'])\n",
    "print(\"Size (sq ft)\")\n",
    "get_stats(dfp['size'])\n",
    "print('assessment')\n",
    "get_stats(dfp['assessment'])\n",
    "print('market')\n",
    "get_stats(dfp['market'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny lot size\n",
    "dfp.loc[dfp['lot_size']<0.02, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large lot size\n",
    "dfp.loc[dfp['lot_size']>10000, :] # this is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small size\n",
    "dfp[dfp['size']<250] # nothing ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large size\n",
    "dfp[dfp['size']>200000] #largest are commercial, industrial, distribution,etc - checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: difference between market and assessment? (market is often >2x assessment value)\n",
    "https://www.realtor.com/advice/sell/assessed-value-vs-market-value-difference/<br>\n",
    "Market: what home could sell for<br>\n",
    "Assessed: Used for property tax<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']<500] #most low values are vacant properties, 5200 radium springs is a power plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['market']>10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[dfp['assessment']<500] #Vacant properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['zoningType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['siteZoningIdent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['propClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['wallType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['roofCover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp['foundationType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Statistical summaries by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g1 = dfp.loc[:,['zoningType','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='zoningType')\n",
    "pd.set_option('precision', 2)\n",
    "dfp_g1.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['propClass','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='propClass')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g2 = dfp.loc[:, ['condition','lot_size', 'yearBuilt', 'size', 'market', 'assessment']].groupby(by='condition')\n",
    "dfp_g2.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g3 = dfp.groupby(by=['condition', 'propClass']) \n",
    "dfp_g3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_g4 = dfp.groupby(by=['siteZoningIdent', 'propClass']) \n",
    "dfp_g4.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read missing back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4410, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.index = range(len(missing))\n",
    "missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dir = '/home/mirabel/Dropbox (GaTech)/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing'\n",
    "#read all json files into a single list\n",
    "j_list=[]\n",
    "flist = os.listdir(missing_dir)\n",
    "flist.sort()\n",
    "for filename in flist:\n",
    "    if filename.endswith('.json'):\n",
    "        f = open(missing_dir+'/'+filename)\n",
    "        j_list.append(json.load(f))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Split the results into 'found', which were retrieved on the second run-through and 'missing_list', which still could not be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = [y for x in j_list for y in x]\n",
    "data_found =[]#The data returned by the attom api\n",
    "orig_addresses = [] #The addresses used to query the attom api\n",
    "missing_list = pd.DataFrame(data={'Address':[], 'StatusMSG':[], 'Code':[]}) #the return values of addresses which were still not coded\n",
    "for i in range(len(data_new)):\n",
    "    if len(data_new[i])==8 or len(data_new[i])==6:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':data_new[i]['msg'], 'Code':data_new[i]['code']}, ignore_index=True)\n",
    "    elif len(data_new[i])==0:\n",
    "        missing_list = missing_list.append({'Address':missing.iloc[i, 1], 'StatusMSG':'unknown', 'Code':0}, ignore_index=True)\n",
    "    else:\n",
    "        data_found.append(data_new[i])\n",
    "        orig_addresses.append(missing.iloc[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': {'obPropId': 32516562613095,\n",
       "  'fips': '13095',\n",
       "  'apn': '64192 01',\n",
       "  'attomId': 325165626},\n",
       " 'lot': {'depth': 0.0,\n",
       "  'frontage': 0.0,\n",
       "  'lotSize1': 0.0,\n",
       "  'lotSize2': 0.0,\n",
       "  'zoningType': 'NP'},\n",
       " 'area': {'countrySecSubd': 'Dougherty County',\n",
       "  'munCode': 'DH',\n",
       "  'munName': 'DOUGHERTY',\n",
       "  'subdTractNum': 0,\n",
       "  'taxCodeArea': 0,\n",
       "  'censusTractIdent': '0',\n",
       "  'censusBlockGroup': '1'},\n",
       " 'address': {'country': 'US',\n",
       "  'countrySubd': 'GA',\n",
       "  'line1': '2415 SYLVESTER HWY',\n",
       "  'line2': 'ALBANY,GA 31705',\n",
       "  'locality': 'Albany',\n",
       "  'matchCode': 'ExaStr',\n",
       "  'oneLine': '2415 SYLVESTER HWY, ALBANY,GA 31705',\n",
       "  'postal1': '31705',\n",
       "  'postal2': '2470',\n",
       "  'postal3': 'C045',\n",
       "  'stateFips': '13'},\n",
       " 'location': {'accuracy': 'Street',\n",
       "  'elevation': 0.0,\n",
       "  'latitude': '31.575671',\n",
       "  'longitude': '-84.091450',\n",
       "  'distance': 0.0,\n",
       "  'geoid': 'CO13095, CS1390996, DB1301830, MT30000457, PL1301052, SB0000080576, SB0000080577, SB0000080585, SB0000080591, ZI31705'},\n",
       " 'summary': {'absenteeInd': 'ABSENTEE(MAIL AND SITUS NOT =)',\n",
       "  'propType': 'UNKNOWN',\n",
       "  'yearBuilt': 0,\n",
       "  'propLandUse': 'UNKNOWN',\n",
       "  'propIndicator': 0,\n",
       "  'REOflag': ''},\n",
       " 'utilities': {},\n",
       " 'sale': {'amount': {'saleAmt': 0.0, 'saleDisclosureType': 0},\n",
       "  'calculation': {'pricePerBed': 0.0, 'pricePerSizeUnit': 0.0}},\n",
       " 'building': {'size': {'bldgSize': 0.0,\n",
       "   'grossSize': 0.0,\n",
       "   'grossSizeAdjusted': 0.0,\n",
       "   'groundFloorSize': 0.0,\n",
       "   'livingSize': 0.0,\n",
       "   'sizeInd': 'BUILDING SQFT ',\n",
       "   'universalSize': 0.0,\n",
       "   'atticSize': 0.0},\n",
       "  'rooms': {'bathFixtures': -1,\n",
       "   'baths1qtr': 0,\n",
       "   'baths3qtr': 0,\n",
       "   'bathsCalc': 0.0,\n",
       "   'bathsFull': 0,\n",
       "   'bathsHalf': 0,\n",
       "   'bathsTotal': 0.0,\n",
       "   'beds': 0,\n",
       "   'roomsTotal': 0},\n",
       "  'interior': {'bsmtSize': 0, 'bsmtFinishedPercent': 0, 'fplcCount': 0},\n",
       "  'construction': {'propertyStructureMajorImprovementsYear': '0'},\n",
       "  'parking': {'prkgSize': 0.0},\n",
       "  'summary': {'levels': 0, 'unitsCount': 0, 'viewCode': ''}},\n",
       " 'assessment': {'appraised': {'apprImprValue': 0.0,\n",
       "   'apprLandValue': 0.0,\n",
       "   'apprTtlValue': 0.0},\n",
       "  'assessed': {'assdImprValue': 61755.0,\n",
       "   'assdLandValue': 0.0,\n",
       "   'assdTtlValue': 61755.0},\n",
       "  'market': {'mktImprValue': 154388.0,\n",
       "   'mktLandValue': 0.0,\n",
       "   'mktTtlValue': 154388.0},\n",
       "  'tax': {'taxAmt': 2705.24,\n",
       "   'taxPerSizeUnit': 0.0,\n",
       "   'taxYear': 2018.0,\n",
       "   'exemption': {'ExemptionAmount1': 0.0,\n",
       "    'ExemptionAmount2': 0.0,\n",
       "    'ExemptionAmount3': 0.0,\n",
       "    'ExemptionAmount4': 0.0,\n",
       "    'ExemptionAmount5': 0.0}},\n",
       "  'delinquentyear': 0,\n",
       "  'improvementPercent': 100,\n",
       "  'fullCashValue': 0,\n",
       "  'owner': {'description': 'not provided',\n",
       "   'owner1': {'lastName': 'REGIONS BANK'},\n",
       "   'owner2': {},\n",
       "   'absenteeOwnerStatus': 'A',\n",
       "   'mailingAddressOneLine': '250 RIVERCHASE PKWY E 6, HOOVER AL 352441832'},\n",
       "  'mortgage': {'FirstConcurrent': {'amount': 0.0, 'interestRate': 0.0},\n",
       "   'SecondConcurrent': {'amount': 0.0},\n",
       "   'ThirdConcurrent': {'amount': 0.0},\n",
       "   'title': {}}},\n",
       " 'vintage': {'lastModified': '2019-6-10', 'pubDate': '2019-6-22'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_found)\n",
    "data_found[685]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'propClass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2c4cfc60f70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Projects that were found when the api was queried again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_found\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m685\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m686\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#get the primary ids in the junction table for each address returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mid_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#maps address to id, from junct table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-71a3ff0230ef>\u001b[0m in \u001b[0;36mprop_split\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m'zoningType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zoningType'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_lot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m'siteZoningIdent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siteZoningIdent'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_lot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;34m'propClass'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'propClass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;34m'yearBuilt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yearBuilt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grossSizeAdjusted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_building\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-71a3ff0230ef>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m'zoningType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zoningType'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_lot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m'siteZoningIdent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siteZoningIdent'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_lot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;34m'propClass'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'propClass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;34m'yearBuilt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yearBuilt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grossSizeAdjusted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_building\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'propClass'"
     ]
    }
   ],
   "source": [
    "#Projects that were found when the api was queried again\n",
    "dfp2 = prop_split(data_found[685:686])\n",
    "dfp2.index = range(len(dfp2))\n",
    "#get the primary ids in the junction table for each address returned\n",
    "id_dict = {df.loc[x,'Address']:df.loc[x, 'Id'] for x in range(len(df))} #maps address to id, from junct table\n",
    "NOT_FOUND = id_dict['NOT FOUND']\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in orig_addresses] #id of each addresss in new dataframe\n",
    "dfp2['PrimaryId'] = prim_ids\n",
    "dfp2.drop_duplicates(subset=\"address\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  In found, compare the coordinates that were located to the coordinates of the address used to query. If it seems that the api found the wrong location, drop this address from dfp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the addresses returned by attom api to those which were queried -> is there a difference?\n",
    "data_found_lat = [float(x['location']['latitude']) for x in data_found]\n",
    "data_found_lon = [float(x['location']['longitude']) for x in data_found]\n",
    "data_found_acc = [x['location']['accuracy'] for x in data_found]\n",
    "df_subset = df[df['Address'].isin(orig_addresses)] #The set of the dataframe that was used to generate data_found\n",
    "df_subset.index = range(len(df_subset))\n",
    "\n",
    "df_compare = pd.DataFrame(data={'found_addresses':dfp2['address'], 'orig_addresses':df_subset['Address'], 'accuracy':data_found_acc,'found_lat':data_found_lat, 'found_lon':data_found_lon, 'orig_lat':df_subset['Xcoord'], 'orig_lon':df_subset['Ycoord']})\n",
    "df_compare['coord_diff'] = df_compare['found_lat']+df_compare['found_lon']-df_compare['orig_lat']-df_compare['orig_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addresses which may have been miscoded: difference in coordinates is significant\n",
    "df_compare[df_compare['coord_diff']>0.005]\n",
    "#US highway addresses: found is more accurate\n",
    "#all else: original is more accurate\n",
    "#Despite incorrect geocoding, likely only the E/W N/S mixups and wildly incorrect addresses are wrong\n",
    "#That is, 80, 97, 190, 553, 676, 734\n",
    "drop_idx = [80, 97, 190, 553, 676, 734]\n",
    "nf_miscoded = dfp2.loc[drop_idx, 'address']\n",
    "dfp2.drop(drop_idx, inplace=True)\n",
    "dfp2.index = range(len(dfp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) In missing_list, split the non-found addresses by the error code. Export the addresses which resulted in 'System not responding' to be re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list.groupby(by='StatusMSG').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list.groupby(by='Code').count()\n",
    "#-2 = System Not Responding : There is a failure within the api\n",
    "#1 = SuccessWithoutResult : Your request was successful but returned no results\n",
    "#210 = Geocoder Search Results Address Not Identified. : The input address could not be identified. Please try again.\n",
    "#212 = \tSuccess without results. No data available for this address. : The input address has been located with ZIP level precision, but a record is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='System Not Responding.'].to_csv('missing_notresponding.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Success without results. No data available for this address.'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list[missing_list['StatusMSG']=='Geocoder Results Address Not Identified.'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Retrieve the results of step c) and add them to a new dataframe dfp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/mirabel/Dropbox/CDS-2019-AlbanyHub/Processed-Data/attom_json/missing/noresponse/json_dump_missing_noresponse0_10.json')\n",
    "data_nr = json.load(f)\n",
    "f.close()\n",
    "dfp3 = prop_split(data_nr)\n",
    "prim_ids=[id_dict.get(x, NOT_FOUND) for x in dfp3['address']] #id of each addresss in new dataframe\n",
    "#manually fix one value\n",
    "prim_ids[6] = id_dict.get('600 POLARIS DR')\n",
    "dfp3['PrimaryId'] = prim_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_all = pd.concat([dfp, dfp2, dfp3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = missing_list[missing_list['StatusMSG']!='System Not Responding.']\n",
    "p2 = p1.append([{'Address':x} for x in nf_miscoded], ignore_index=True)\n",
    "#\n",
    "p2.tail(20)\n",
    "p2.to_csv('missing_unresolved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "cds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
